# Rate Limiting System â€“ Low Level Design (LLD)

## ğŸ“Œ Overview

This project implements a **rate limiting library** designed to be plugged into an API service to control incoming requests.

The library:

* Supports **per-user** and **per-endpoint** rate limits
* Supports **multiple rate limiting algorithms**
* Is **extensible, configurable, and cleanly separated** using LLD best practices
* Focuses on **design clarity**, not infrastructure (no Redis, no networking)

This design is suitable for **LLD interviews** and demonstrates strong separation of concerns and use of design patterns.

---

## ğŸ¯ Problem Statement

> Design a rate limiting library that can be used by an API service to restrict incoming requests.
> The library should support per-user and per-endpoint limits, and allow different rate limiting strategies to be configured dynamically.

---

## ğŸ§  High-Level Design Principles

* **Separation of Concerns**

    * Configuration â‰  Runtime State â‰  Enforcement Logic
* **Open/Closed Principle**

    * New algorithms can be added without changing existing code
* **Strategy Pattern**

    * Each rate limiting algorithm is encapsulated in its own strategy
* **Factory Pattern**

    * Strategy selection is done dynamically based on configuration
* **Clean Boundaries**

    * No HTTP, framework, or infrastructure logic inside the core library

---

## ğŸ“‚ Project Structure

```
org.example
â”œâ”€â”€ controller
â”‚     â””â”€â”€ RateLimitController
â”‚
â”œâ”€â”€ dto
â”‚     â”œâ”€â”€ RequestContext
â”‚     â””â”€â”€ RateLimitResponse
â”‚
â”œâ”€â”€ config
â”‚     â””â”€â”€ RateLimitConfig
â”‚
â”œâ”€â”€ enums
â”‚     â”œâ”€â”€ RateLimitStrategyType
â”‚     â”œâ”€â”€ Status
â”‚     â””â”€â”€ UserType
â”‚
â”œâ”€â”€ service
â”‚     â”œâ”€â”€ RateLimitService
â”‚     â””â”€â”€ ConfigProvider
â”‚
â”œâ”€â”€ strategy
â”‚     â”œâ”€â”€ RateLimittingStrategy
â”‚     â”œâ”€â”€ TokenBucketStrategy
â”‚     â””â”€â”€ (other strategies can be added)
â”‚
â”œâ”€â”€ state
â”‚     â”œâ”€â”€ RateLimitState
â”‚     â””â”€â”€ TokenBucketState
â”‚
â”œâ”€â”€ store
â”‚     â”œâ”€â”€ RateLimitStore
â”‚     â””â”€â”€ InMemoryRateLimitStateStore
â”‚
â””â”€â”€ Main
```

---

## ğŸ§© Core Concepts

### 1ï¸âƒ£ RateLimitConfig (Static Rules)

Represents **what is allowed**.

```java
public class RateLimitConfig {
    String endpoint;
    Integer maxRequest;
    Long timeWindow;
    RateLimitStrategyType strategy;
}
```

* Immutable
* Loaded at startup
* Does **not** change at runtime
* Does **not** store counters or timestamps

---

### 2ï¸âƒ£ RateLimitState (Runtime Usage)

Represents **what has already happened** for a specific key (e.g. `userId:endpoint`).

Example for Token Bucket:

* Available tokens
* Last refill timestamp

State is:

* Mutable
* Algorithm-specific
* Managed by strategies

---

### 3ï¸âƒ£ RateLimittingStrategy (Behavior)

Defines **how rate limiting is evaluated**.

```java
public interface RateLimittingStrategy {
    Status evaluateRequest(
        RateLimitConfig config,
        RequestContext requestContext
    );
}
```

Each algorithm (Token Bucket, Fixed Window, etc.) has its own implementation.

---

### 4ï¸âƒ£ RateLimitStore (State Persistence)

Abstracts **where runtime state is stored**.

```java
public interface RateLimitStore {
    RateLimitState getState(String key);
    void updateState(String key, RateLimitState state);
    void remove(String key);
}
```

* Keeps strategies storage-agnostic
* In-memory implementation provided
* Can later be replaced with Redis or DB (out of scope for LLD)

---

### 5ï¸âƒ£ StrategyFactory (Enum â†’ Strategy Mapping)

Maps configuration (`enum`) to actual strategy objects.

```text
RateLimitStrategyType.TOKEN_BUCKET â†’ TokenBucketStrategy
```

This keeps:

* Configuration lightweight
* Behavior decoupled
* System extensible

---

## ğŸ”„ Request Flow

1. API receives a request
2. `RequestContext` is created (user, endpoint, user type)
3. `ConfigProvider` resolves applicable `RateLimitConfig`
4. `StrategyFactory` selects the correct strategy
5. Strategy:

    * Fetches state from `RateLimitStore`
    * Evaluates the request
    * Updates state if allowed
6. `RateLimitResponse` is returned (`ALLOWED` / `DENIED`)

---

## ğŸ“Œ Example Scenario

**Rule**
User `U1` can call `/login` only **1 time per second**

**Flow**

* First request â†’ token available â†’ ALLOWED
* Second request within same second â†’ no token â†’ DENIED
* After 1 second â†’ token refilled â†’ ALLOWED

Config remains unchanged, state evolves per request.

---

## ğŸ—ï¸ Extensibility

### Add a new algorithm

1. Create a new `RateLimittingStrategy` implementation
2. Add corresponding state class (if needed)
3. Register it in `StrategyFactory`

No existing code needs modification.

---

## ğŸš« Out of Scope (Intentionally)

* Distributed systems (Redis, Lua, etc.)
* Thread safety
* HTTP status codes
* Cloud / infra concerns

These belong to **HLD**, not LLD.

---

## ğŸ¤ Interview Takeaway

> â€œThe design cleanly separates configuration, runtime state, and enforcement logic.
> It uses Strategy and Factory patterns to support multiple algorithms while keeping the system extensible and easy to reason about.â€

---

## âœ… Status

âœ” LLD complete
âœ” Interview-ready
âœ” Clean abstractions
âœ” Easily extensible
